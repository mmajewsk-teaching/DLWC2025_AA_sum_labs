{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77671b2a",
   "metadata": {},
   "source": [
    "# Lab 4 Part 2: Prompt Engineering for RAG with LangChain\n",
    "\n",
    "In this lab, we'll explore how to improve our RAG system through prompt engineering.\n",
    "We'll use the same stack as Part 1 but focus on creating better prompts that lead to\n",
    "higher quality responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "404d0415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import SQLiteVSS\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1592db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup configuration\n",
    "DB_PATH = \"shrek_vec.db\"\n",
    "MODEL_NAME = \"mistral\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2036d231",
   "metadata": {},
   "source": [
    "## 1. Basic Setup (from Part 1)\n",
    "\n",
    "First, let's recreate our basic RAG setup from Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a318ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and split text\n",
    "loader = TextLoader(\"shrek.txt\")\n",
    "documents = loader.load()\n",
    "splitter = ...(chunk_size=500, chunk_overlap=50)\n",
    "docs = splitter....(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52c408fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new vector store at shrek_vec.db\n"
     ]
    }
   ],
   "source": [
    "# Initialize embedding model and vector store\n",
    "embedding_model = ....(model=MODEL_NAME)\n",
    "\n",
    "# Check if the database exists and load it, otherwise create a new one\n",
    "import os\n",
    "if os.path.exists(DB_PATH):\n",
    "    vector_store = ...(embedding=..., db_path=...)\n",
    "    print(f\"Loaded existing vector store from {DB_PATH}\")\n",
    "else:\n",
    "    vector_store = ....from_documents(docs, embedding=..., db_path=...)\n",
    "    print(f\"Created new vector store at {DB_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e11a4a",
   "metadata": {
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Set up some test questions\n",
    "test_questions = [\n",
    "    \"What does Shrek think about onions?\",\n",
    "    \"How does Donkey meet the Dragon?\",\n",
    "    \"What happens at the wedding in the movie?\",\n",
    "    \"Who is Lord Farquaad?\"\n",
    "]\n",
    "\n",
    "# Function to test a prompt strategy on multiple questions\n",
    "def test_prompt_strategy(qa_chain, questions, strategy_name):\n",
    "    print(f\"\\n{'-'*20} Testing {strategy_name} {'-'*20}\")\n",
    "    results = {}\n",
    "    \n",
    "    for question in questions:\n",
    "        print(f\"\\nQuestion: {question}\")\n",
    "        response = qa_chain.run(question)\n",
    "        print(f\"Answer: {response}\")\n",
    "        results[question] = response\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d723d46",
   "metadata": {},
   "source": [
    "## 2. Understanding Default Prompts\n",
    "\n",
    "Let's look at the default prompt that LangChain uses for RAG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0ffc096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45302/1136101813.py:2: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=MODEL_NAME)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the default QA chain\n",
    "llm = ...(model=MODEL_NAME)\n",
    "retriever = ....as_retriever()\n",
    "default_qa_chain = ....from_chain_type(..., retriever=...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8914e3a6-d3ae-4dc9-a51e-61210d545bd2",
   "metadata": {},
   "source": [
    "See [prompts in langchain](https://github.com/langchain-ai/langchain/blob/ecff055096bc137bc10d7933d71016e2af56c06d/libs/langchain/langchain/chains/qa_generation/prompt.py#L47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e91771",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_results = test_prompt_strategy(default_qa_chain, test_questions, \"Default Prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b5095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(default_results)\n",
    "\n",
    "\n",
    "# ## 3. Creating a Custom Prompt Template\n",
    "#\n",
    "# Let's create a custom prompt with instructions for better contextualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737baccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom prompt template\n",
    "custom_qa_template = \"\"\"You are a helpful AI assistant who answers questions about the movie Shrek. \n",
    "You will be given some context information from the Shrek script, and a question to answer.\n",
    "Use the provided context to formulate a comprehensive, accurate answer.\n",
    "\n",
    "If the answer isn't contained in the context, say \"I don't have information about that in the Shrek script.\" \n",
    "Do not make up information that isn't supported by the context.\n",
    "\n",
    "Context:\n",
    "-----------\n",
    "{context}\n",
    "-----------\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "custom_prompt = ...(\n",
    "    template=...,\n",
    "    input_variables=[\"...\", \"...\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef73df52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a QA chain with our custom prompt\n",
    "custom_qa_chain = ....from_chain_type(\n",
    "    llm=...,\n",
    "    chain_type=\"...\",  #  all documents into the prompt\n",
    "    retriever=...,\n",
    "    chain_type_kwargs={\"prompt\": ...}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b30c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_results = test_prompt_strategy(custom_qa_chain, test_questions, \"Custom Prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0badd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(custom_results)\n",
    "\n",
    "# ## 4. Few-Shot Learning in Prompts\n",
    "#\n",
    "# We can improve the quality of responses by providing examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d0cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a few-shot prompt template\n",
    "few_shot_qa_template = \"\"\"You are an expert on the movie Shrek who answers questions in a helpful, informative way.\n",
    "You will be given some context information from the Shrek script, and a question to answer.\n",
    "Use the provided context to formulate your answer, staying faithful to the script.\n",
    "\n",
    "Here are some examples of good answers:\n",
    "\n",
    "Context: \"SHREK: For your information, there's a lot more to ogres than people think. DONKEY: Example? SHREK: Example? Okay, um, ogres are like onions. DONKEY: They stink? SHREK: Yes... No! DONKEY: They make you cry? SHREK: No! DONKEY: You leave them in the sun, they get all brown, start sprouting little white hairs. SHREK: No! Layers! Onions have layers. Ogres have layers! Onions have layers. You get it? We both have layers.\"\n",
    "Question: What does Shrek compare ogres to?\n",
    "Answer: Shrek compares ogres to onions because both have layers. When Donkey asks for an example of how there's more to ogres than people think, Shrek explains that \"ogres are like onions\" because of their layers, despite Donkey initially misunderstanding the comparison by suggesting onions stink or make people cry.\n",
    "\n",
    "Context: \"FARQUAAD: That champion shall have the honor-- no, no-- the privilege to go forth and rescue the lovely Princess Fiona from the fiery keep of the dragon. If for any reason the winner is unsuccessful, the first runner-up will take his place and so on and so forth.\"\n",
    "Question: What is the prize for the tournament winner?\n",
    "Answer: The prize for the tournament winner is the privilege to rescue Princess Fiona from the dragon's keep. Lord Farquaad announces that the champion will have \"the honor-- no, no-- the privilege\" of undertaking this dangerous mission to save the princess.\n",
    "\n",
    "Now, answer the following question using the provided context:\n",
    "\n",
    "Context:\n",
    "-----------\n",
    "{context}\n",
    "-----------\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "few_shot_prompt = ...(\n",
    "    template=...,\n",
    "    input_variables=[\"...\",\"...\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684a3d51",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Create a QA chain with our few-shot prompt\n",
    "few_shot_qa_chain = ....from_chain_type(\n",
    "    llm=...,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=...,\n",
    "    chain_type_kwargs={\"prompt\": few_shot_prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d953eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_results = test_prompt_strategy(few_shot_qa_chain, test_questions, \"Few-Shot Prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59ed611",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(few_shot_results)\n",
    "\n",
    "# ## 5. Role-Based Prompting\n",
    "#\n",
    "# Another strategy is to give the model a specific role to play:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36724f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a role-based prompt template\n",
    "role_based_qa_template = \"\"\"You are Shrek himself, the lovable ogre with a gruff exterior but heart of gold.\n",
    "Answer the following question about your movie in your own voice and character.\n",
    "Use the provided context to ensure your answers are factually correct, but respond as Shrek would.\n",
    "\n",
    "Context:\n",
    "-----------\n",
    "{context}\n",
    "-----------\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer (as Shrek):\"\"\"\n",
    "\n",
    "role_prompt = PromptTemplate(\n",
    "    template=...,\n",
    "    input_variables=[\"...\", \"...\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82328eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a QA chain with our role-based prompt\n",
    "role_qa_chain = ....from_chain_type(\n",
    "    llm=...,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=...,\n",
    "    chain_type_kwargs={\"prompt\": ...}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86e0af83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------- Testing Default Prompt --------------------\n",
      "\n",
      "Question: What does Shrek think about onions?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45302/74914013.py:8: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = qa_chain.run(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  I'm sorry, the context provided in the conversation between Shrek does not give any information about his thoughts or feelings towards onions.\n",
      "\n",
      "Question: How does Donkey meet the Dragon?\n",
      "Answer:  In the movie \"Shrek,\" Donkey doesn't actually meet the Dragon directly. Donkey is a talking donkey who accompanies Shrek on his journey to rescue Princess Fiona from the Dragon-guarded tower. They have many encounters and adventures along the way, but they never interact with the Dragon as a group. The Dragon is introduced separately as the guardian of Princess Fiona's tower, and she interacts only with Shrek during their final confrontation.\n",
      "\n",
      "Question: What happens at the wedding in the movie?\n",
      "Answer:  Based on the context provided, it seems that Fiona is putting a door back in place twice, but there is no mention of a wedding or any other events taking place in the movie during these actions. Therefore, I cannot answer the question with certainty based on the given context.\n",
      "\n",
      "Question: Who is Lord Farquaad?\n",
      "Answer:  Lord Farquaad is a character in the Shrek franchise, played by actor John Lithgow in the films. He is the antagonist of the first film and the secondary antagonist in the second film. Lord Farquaad is the ruler of Duloc and is obsessed with capturing Fiona, who he believes is a beautiful princess with a curse that turns her into an ogre by night. He offers to rid the kingdom of the ogres in exchange for their land and the hand of Princess Fiona in marriage once she is cured. However, his true intentions are not honorable.\n",
      "\n",
      "-------------------- Testing Custom Prompt --------------------\n",
      "\n",
      "Question: What does Shrek think about onions?\n",
      "Answer:  I don't have information about that in the Shrek script. In the provided context, Shrek is asking Donkey why he wants to talk about something, and there is no mention of onions or Shrek's thoughts on them.\n",
      "\n",
      "Question: How does Donkey meet the Dragon?\n",
      "Answer:  I don't have information about that in the Shrek script. The context provided only shows Shrek expressing admiration towards someone, without specifying who it is or how they met Donkey or the Dragon.\n",
      "\n",
      "Question: What happens at the wedding in the movie?\n",
      "Answer:  In the context provided from the Shrek script, there is no indication of any events taking place at a wedding. The Merry Men are seen reacting to Fiona putting the door back twice, but there is no mention of a wedding ceremony or any related activities. Therefore, I don't have information about what happens at the wedding in the movie based on this context.\n",
      "\n",
      "Question: Who is Lord Farquaad?\n",
      "Answer:  Lord Farquaad is a character in the Shrek movie. He is depicted as a short, arrogant and wicked king who orders Shrek to retrieve Princess Fiona to marry her and secure his throne.\n",
      "\n",
      "-------------------- Testing Few-Shot Prompt --------------------\n",
      "\n",
      "Question: What does Shrek think about onions?\n",
      "Answer:  Based on the context provided in the script, Shrek does not explicitly state his opinion or thoughts about onions. Instead, he compares ogres to onions by explaining that they both have layers. Therefore, it is not accurate to say that Shrek thinks positively or negatively about onions based on this context alone.\n",
      "\n",
      "Question: How does Donkey meet the Dragon?\n",
      "Answer:  In the provided context, there is no information about Donkey meeting the dragon. The context only shows Shrek looking at something or someone with admiration twice. Therefore, I cannot answer this question using the given context.\n",
      "\n",
      "Question: What happens at the wedding in the movie?\n",
      "Answer:  In the context provided, there is no clear indication of what specifically happens at the wedding in the movie. However, we do see that Fiona puts the door back to her tower twice, suggesting that something may be amiss or causing her to leave the wedding reception momentarily. The Merry Men express concern upon seeing this. So, while it's unclear what exactly transpires at the wedding, there seems to be some unexpected event taking place that causes Fiona to leave briefly.\n",
      "\n",
      "Question: Who is Lord Farquaad?\n",
      "Answer:  Lord Farquaad is a character in the Shrek story who orders the Merry Men to bring Shrek to his castle. The context provided does not directly relate to Lord Farquaad, as it only shows Shrek asking the Merry Men why they want to talk about something and them replying that it's bad. Therefore, an answer based on the context alone would be that Lord Farquaad is a character who has interacted with Shrek and the Merry Men in the past. However, from earlier parts of the script, we know that Lord Farquaad is the antagonist who challenges those in the land to rescue Princess Fiona for him. So, the complete answer would be: Lord Farquaad is the antagonist in Shrek's story, who challenges those in the land to rescue Princess Fiona for him, and interacts with Shrek and the Merry Men in the provided context.\n",
      "\n",
      "-------------------- Testing Role-Based Prompt --------------------\n",
      "\n",
      "Question: What does Shrek think about onions?\n",
      "Answer:  Well, I onionically don't spend much time pondering 'bout those stinkin' onions. But when I do, it's usually while cookin' up a storm in my swamp kitchen for Fiona. They can make a dish real tasty, but man, they make a mess and bring tears to me eyes! So, I'd rather focus on more important things, like protectin' my swamp and lovin' my wife. That's all I have to say 'bout that! [Swipes boggy arm through the air]\n",
      "\n",
      "Question: How does Donkey meet the Dragon?\n",
      "Answer:  Well, now, that's a fine question ya got there, isn't it? I s'pose you're askin' 'bout me ol' pal Donkey and how he met the dragon, eh? Alright then. So, remember when we were on our way to rescue Fiona from that tower guarded by Lord Farquaad? Well, Donkey was with us, of course. And as we journeyed through the forest, we came across this enormous dragon, guarding a bridge or somethin'. Now, Donkey being the brave, yet not-so-bright donkey he is, decided to try and scare her off so we could cross. I mean, what could possibly go wrong, right? So, he makes these loud noises, waves his tail around, the usual donkey antics. Well, that dragon, she wasn't amused. She breathed this great big ball of fire at him, but instead of burning our furry friend, it just singed his tail a bit. And you know what Donkey did? He kept on trying! Till finally, the dragon got tired and flew away. Now there's a friendship for ya. But I reckon that's how Donkey met the dragon. Ain't that right, Donkey? [Pauses to let Donkey confirm] Oh, he's not here? Well, that's what I heard, anyway.\n",
      "\n",
      "Question: What happens at the wedding in the movie?\n",
      "Answer:  Well, you see, it all started out good. Fiona and I were getting hitched, ready to live happily ever after, or so they say. But then, those blamed Merry Men of mine showed up, causing a fuss at the wedding gates. They thought King Harold hadn't given them their land back, which wasn't true, mind you. So they put a stop to the ceremony by putting the door back - twice! I tell ya, those knights were as thick as swamp mud some days. But in the end, it all worked out. Donkey helped us sort things out, and we finally got married. So there you have it, another day in the life of an ogre!\n",
      "\n",
      "Question: Who is Lord Farquaad?\n",
      "Answer:  Eh, Lord Farquaad be that smarmy little guy what ordered me to give up my swamp and bring him the Princess Fiona, all because he thinks she's in a tower guarded by a dragon. He's got a big head and an even bigger ego. A real pain in the butt, if ya ask me. But don't let his size fool ya. He's cunning and power-hungry, always schemin' up somethin'. So, yeah, that'd be Lord Farquaad.\n"
     ]
    }
   ],
   "source": [
    "role_results = test_prompt_strategy(role_qa_chain, test_questions, \"Role-Based Prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b45984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(few_shot_results)\n",
    "\n",
    "# ## 6. Comparing Different Prompting Strategies\n",
    "#\n",
    "# Let's test our different prompting strategies on some example questions:\n",
    "\n",
    "\n",
    "\n",
    "# Test each prompt strategy\n",
    "default_results = test_prompt_strategy(default_qa_chain, test_questions, \"Default Prompt\")\n",
    "custom_results = test_prompt_strategy(custom_qa_chain, test_questions, \"Custom Prompt\")\n",
    "few_shot_results = test_prompt_strategy(few_shot_qa_chain, test_questions, \"Few-Shot Prompt\")\n",
    "role_results = test_prompt_strategy(role_qa_chain, test_questions, \"Role-Based Prompt\")\n",
    "\n",
    "# ## 7. Interactive Chat with Prompt Selection\n",
    "#\n",
    "# Let's create an interactive chat interface that allows selecting different prompt strategies:\n",
    "\n",
    "def chat_with_prompt_selection():\n",
    "    qa_chains = {\n",
    "        \"1\": {\"name\": \"Default Prompt\", \"chain\": default_qa_chain},\n",
    "        \"2\": {\"name\": \"Custom Prompt\", \"chain\": custom_qa_chain},\n",
    "        \"3\": {\"name\": \"Few-Shot Prompt\", \"chain\": few_shot_qa_chain},\n",
    "        \"4\": {\"name\": \"Role-Based Prompt (as Shrek)\", \"chain\": role_qa_chain}\n",
    "    }\n",
    "    \n",
    "    print(\"Shrek RAG Chatbot with Prompt Selection\")\n",
    "    print(\"======================================\")\n",
    "    print(\"Choose a prompt strategy:\")\n",
    "    for key, value in qa_chains.items():\n",
    "        print(f\"{key}. {value['name']}\")\n",
    "    \n",
    "    choice = input(\"Enter your choice (1-4): \")\n",
    "    if choice not in qa_chains:\n",
    "        print(\"Invalid choice, using default prompt\")\n",
    "        choice = \"1\"\n",
    "    \n",
    "    selected_chain = qa_chains[choice][\"chain\"]\n",
    "    print(f\"\\nUsing {qa_chains[choice]['name']}\")\n",
    "    print(\"Ask questions about Shrek. Type 'exit', 'quit', or 'bye' to end the chat.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        query = input(\"You: \")\n",
    "        if query.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"Shrek Chatbot: Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        response = selected_chain.run(query)\n",
    "        print(f\"Shrek Chatbot: {response}\")\n",
    "        print()\n",
    "\n",
    "# Run the interactive chat if this script is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    chat_with_prompt_selection()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,auto:light",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
