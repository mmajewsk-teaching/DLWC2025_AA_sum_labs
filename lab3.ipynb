{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd0c7e83-063b-4f9f-8504-87603e7de225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.decomposition import PCA\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e1e19c-d75f-4c61-8739-163115560724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f654056b-fdbe-4ae6-a32e-f0e980c0bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if it doesnt work\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "144b0f0d-adae-44e0-91e0-38a698b44980",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb282241-ee70-406b-8b09-74f1f267ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_path = \"shrek.txt\"\n",
    "\n",
    "with open(script_path, 'r', encoding='utf-8') as file:\n",
    "    script_text = file.read()\n",
    "import re\n",
    "script_text = re.sub(' +', ' ', script_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb2e6a42-f15a-4e84-acea-ed9350d52e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fixed_size_chunks(text, chunk_size=1000, overlap=0):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    text_length = len(text)\n",
    "    while start < text_length:\n",
    "        end = min(start+chunk_size, text_length)\n",
    "        if start>0 and overlap >0:\n",
    "            start = start - overlap\n",
    "        chunks.append(text[start:end])\n",
    "        start = end\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8aa6d037-14ae-49a8-afa5-e85ea5ae0128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/mwm/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "#nltk.data.find('tokenizers/punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8b10747-4b3b-4563-b429-8c9e5d4e25b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentence_chunks(text, sentences_per_chunk=10):\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    for i in range(0, len(sentences), sentences_per_chunk):\n",
    "        chunk = \" \".join(sentences[i:i+sentences_per_chunk])\n",
    "        chunks.append(chunk)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ec6bd5-727c-4e6f-a29b-c9b71d97e0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c6f8342-1358-4c02-a52b-870db2cd3459",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_sentences = create_sentence_chunks(script_text, sentences_per_chunk=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73e84e8c-c652-43b3-bfc2-d9b9fc1e6d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_fixed_size = create_fixed_size_chunks(script_text)\n",
    "chunks_fixed_size_overlapping = create_fixed_size_chunks(script_text, overlap=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "144f8323-ad81-4841-abaa-7cb88cf346bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(texts, tokenizer, model):\n",
    "    encoded_inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded_inputs)\n",
    "    token_embeddings = outputs.last_hidden_state\n",
    "    embeddings = torch.mean(token_embeddings, dim=1)\n",
    "    return embeddings.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7bc02182-bd1d-4712-99d3-09b149607d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_fixed_size = get_embeddings(chunks_fixed_size, tokenizer, model)\n",
    "embeddings_fixed_size_overlapping = get_embeddings(chunks_fixed_size_overlapping, tokenizer, model)\n",
    "embeddings_sentences= get_embeddings(chunks_sentences, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "40a98614-e8be-4b49-897b-e3e512709384",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = lambda a,b: np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "dot_product_similarity = lambda a,b: a@b\n",
    "euclidean_similarity = lambda a,b: 1/(1+ np.linalg.norm(a - b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b92048ba-6eee-43ca-b0ee-aeaa25cb75ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_chunks(query_embedding, chunk_embeddings, chunks, top_k=3, similarity_fn=cosine_similarity):\n",
    "    similarities = []\n",
    "    for i, chunk_embedding in enumerate(chunk_embeddings):\n",
    "        similarity = similarity_fn(query_embedding, chunk_embedding)\n",
    "        similarities.append((i, similarity, chunks[i]))\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "197aa94f-b125-4d3b-9032-8bcd5e256ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(62,\n",
       "  0.41985932,\n",
       "  \"shock. He looks past her and \\n spots a group approaching.) Ah, right \\n on time. Princess, I've brought you \\n a little something.\\n \\n Farquaad has arrived with a group of his men. He looks very regal \\n sitting up on his horse. You would never guess that he's only \\n like 3 feet tall. Donkey wakes up with a yawn as the soldiers \\n march by.\\n \\n DONKEY\\n What'd I miss? What'd I miss? (spots \\n the soldiers) (muffled) Who said that? \\n Couldn't have been the donkey.\\n \\n FARQUAAD\\n Princess Fiona.\\n\\n SHREK\\n As promised. Now hand it over.\\n\\n FARQUAAD\\n Very well, ogre. (holds out a piece \\n of paper) The deed to your swamp, cleared \\n out, as agreed. Take it and go before \\n I change my mind. (Shrek takes the paper) \\n Forgive me, Princess, for startling \\n you, but you startled me, for I have \\n never seen such a radiant beauty before. \\n I'm Lord Farquaad.\\n \\n FIONA\\n Lord Farquaad? Oh, no, no. (Farquaad \\n snaps his fingers) Forgive me, my lord, \\n for I was just saying a short... (Watches \\n as Farquaad is lifted off his horse \\n and set down in front of her. H\"),\n",
       " (63,\n",
       "  0.4018857,\n",
       "  \"ed off his horse \\n and set down in front of her. He comes \\n to her waist.) farewell.\\n \\n FARQUAAD\\n Oh, that is so sweet. You don't have \\n to waste good manners on the ogre. It's \\n not like it has feelings.\\n \\n FIONA\\n No, you're right. It doesn't.\\n\\n Donkey watches this exchange with a curious look on his face.\\n \\n \\n FARQUAAD\\n Princess Fiona, beautiful, fair, flawless \\n Fiona. I ask your hand in marriage. \\n Will you be the perfect bride for the \\n perfect groom?\\n \\n FIONA\\n Lord Farquaad, I accept. Nothing would \\n make - -\\n \\n FARQUAAD\\n (interrupting) Excellent! I'll start \\n the plans, for tomorrow we wed!\\n \\n FIONA\\n No! I mean, uh, why wait? Let's get \\n married today before the sun sets.\\n \\n \\n FARQUAAD\\n Oh, anxious, are you? You're right. \\n The sooner, the better. There's so much \\n to do! There's the caterer, the cake, \\n the band, the guest list. Captain, round \\n up some guests! (a guard puts Fiona \\n on the back of his horse)\\n \\n FIONA\\n Fare-thee-well, ogre.\\n\\n Farquaad's whole party begins to head back to DuLoc. Donkey watches \\n them go.\\n \\n DONK\"),\n",
       " (72,\n",
       "  0.40129653,\n",
       "  \"rds! \\n I order you to get that out of my sight \\n now! Get them! Get them both!\\n \\n The guards run in and separate Fiona and Shrek. Shrek fights \\n them.\\n \\n SHREK\\n No, no!\\n\\n FIONA\\n Shrek!\\n\\n FARQUAAD\\n This hocus-pocus alters nothing. This \\n marriage is binding, and that makes \\n me king! See? See?\\n \\n FIONA\\n No, let go of me! Shrek!\\n\\n SHREK\\n No!\\n\\n FARQUAAD\\n Don't just stand there, you morons.\\n \\n \\n SHREK\\n Get out of my way! Fiona! Arrgh!\\n\\n FARQUAAD\\n I'll make you regret the day we met. \\n I'll see you drawn and quartered! You'll \\n beg for death to save you!\\n \\n FIONA\\n No, Shrek!\\n\\n FARQUAAD\\n (hold a dagger to Fiona's throat) And \\n as for you, my wife...\\n \\n SHREK\\n Fiona!\\n\\n FARQUAAD\\n I'll have you locked back in that tower \\n for the rest of your days! I'm king!\\n \\n \\n Shrek manages to get a hand free and he whistles.\\n\\n FARQUAAD\\n I will have order! I will have perfection! \\n I will have - - (Donkey and the dragon \\n show up and the dragon leans down and \\n eats Farquaad) Aaaah! Aah!\\n \\n DONKEY\\n All right. Nobody move. I got a dragon \\n here, and I'm not \")]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_query = \"Who is farquads wife.\"+\" DONKEY\"\n",
    "\n",
    "query_embedding = get_embeddings([sample_query], tokenizer, model)[0]\n",
    "em = embeddings_fixed_size_overlapping\n",
    "ch = chunks_fixed_size_overlapping\n",
    "retrieve_chunks(query_embedding, em, ch, top_k=3, similarity_fn=cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ed3223-ab82-4108-9d3f-7b38980e3d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
